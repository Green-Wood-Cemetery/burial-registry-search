{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis of the Greenwood Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Exploratory Data Analysis is being done to help with the spot check of certain columns to identify data that needs to be fixed.\n",
    "\n",
    "We will follow the steps below:\n",
    "- Load all the volumes data into one DataFrame\n",
    "- Select the columns that we are going to work on\n",
    "- Identify the unique values on each column with the counts\n",
    "- Will select the burial records that contains the cases we want to fix\n",
    "- Fix the records\n",
    "- Generate a new json file with the fixes to update our interments index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import duckdb\n",
    "\n",
    "%load_ext sql"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the sql database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql duckdb:///sqlite/db.duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SET GLOBAL pandas_analyze_sample=600000\n",
    "\n",
    "%config SqlMagic.feedback = False\n",
    "%config SqlMagic.displaycon = False\n",
    "\n",
    "load_volumes = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading all volumes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to load all volumes json files into one single in memory structure called DataFrame, that will give us analytical capabilities to identify the values on each column and to fix, if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_volumes:\n",
    "  records = []\n",
    "  for file in os.listdir('json'):\n",
    "    records.append(pd.read_json(os.path.join('json',file)))\n",
    "\n",
    "  df = pd.concat(records)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to import into duckdb, to be able to use SQL to do our validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_volumes:\n",
    "  %sql drop table if exists interments;\n",
    "\n",
    "  %sql create table interments as select * from df;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Columns to Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step to identify the columns we want to work with. We will do this by looking the columns in the search filters of the website.\n",
    "The columns we identify there are:\n",
    "- date of interment\n",
    "- birthplace\n",
    "- marital status\n",
    "- age at death\n",
    "- late residence\n",
    "- place of death\n",
    "- cause of death\n",
    "- date of death\n",
    "- undertaker\n",
    "- burial registry\n",
    "- lot number"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to list the columns on our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interment_id, registry_image, interment_date_month_transcribed, interment_date_day_transcribed, interment_date_year_transcribed, interment_date_display, interment_date_iso, \n",
      "name_transcribed, name_display, name_last, name_first, name_middle, name_salutation, name_suffix, \n",
      "is_lot_owner, gender_guess, burial_location_lot_transcribed, burial_location_lot_current, burial_location_lot_previous, burial_location_grave_transcribed, burial_location_grave_current, \n",
      "burial_location_grave_previous, birth_place_transcribed, birth_place_displayed, birth_geo_formatted_address, birth_geo_is_faulty, birth_geo_street_number, birth_geo_street_name_long, \n",
      "birth_geo_street_name_short, birth_geo_neighborhood, birth_geo_city, birth_geo_county, birth_geo_state_short, birth_geo_state_long, birth_geo_country_long, \n",
      "birth_geo_country_short, birth_geo_zip, birth_geo_place_id, birth_geo_formatted_address_extra, birth_place_geo_location, age_years_transcribed, age_months_transcribed, \n",
      "age_days_transcribed, age_hours_transcribed, age_display, age_years, age_months, age_days, age_hours, \n",
      "marital_status_married_transcribed, marital_status_single_transcribed, marital_status, residence_place_city_transcribed, residence_place_city_display, residence_place_street_transcribed, residence_place_street_display, \n",
      "residence_place_geo_formatted_address, residence_place_geo_is_faulty, residence_place_geo_street_number, residence_place_geo_street_number_long, residence_place_geo_street_number_short, residence_place_geo_neighborhood, residence_place_geo_city, \n",
      "residence_place_geo_county, residence_place_geo_state_short, residence_place_geo_state_long, residence_place_geo_country_long, residence_place_geo_country_short, residence_place_geo_zip, residence_place_geo_place_id, \n",
      "residence_place_geo_formatted_address_extra, residence_place_geo_location, death_place_transcribed, death_place_display, death_place_geo_formatted_address, death_place_geo_is_faulty, death_place_geo_street_number, \n",
      "death_place_geo_street_number_long, death_place_geo_street_number_short, death_place_geo_neighborhood, death_place_geo_city, death_place_geo_county, death_place_geo_state_short, death_place_geo_state_long, \n",
      "death_place_geo_country_long, death_place_geo_country_short, death_place_geo_zip, death_place_geo_place_id, death_place_geo_formatted_address_extra, death_place_geo_location, death_date_month_transcribed, \n",
      "death_date_day_transcribed, death_date_year_transcribed, death_date_display, death_date_iso, death_date_ult_month, cause_of_death_transcribed, cause_of_death_display, \n",
      "undertaker_transcribed, undertaker_display, remarks_transcribed, remarks_display, burial_origin, has_diagram, cemetery, \n",
      "registry_volume, death_day, death_month, death_year, registry_page, display_title, birth_day, \n",
      "birth_month, birth_year, birth_circa, birth_city, birth_state, birth_state_full, birth_county, \n",
      "birth_country, birth_country_full, birth_place, birth_lat, birth_lon, biographical_text, gravestone_transcription, \n",
      "death_cause, comments, death_date, death_city, death_county, death_state, death_state_full, \n",
      "place_of_death, death_lat, death_lon, death_certificate, death_circa, forename, surname, \n",
      "maiden_name, middle_name, obit_day, obit_month, obit_source, obit_transcription, obit_year, \n",
      "notes, grave_location, sources, "
     ]
    }
   ],
   "source": [
    "if load_volumes:\n",
    "  columns = df.columns.to_list()\n",
    "\n",
    "  for idx, column in enumerate(columns):\n",
    "    print(column,end=', ')\n",
    "    if (idx+1) % 7 == 0:\n",
    "        print('')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to map the columns we want.\n",
    "- date of interment = interment_date_year_transcribed\n",
    "- birthplace = birth_place_display\n",
    "- marital status = marital_status [x]\n",
    "- age at death = age_years [x]\n",
    "- late residence = residence_place_city_display\n",
    "- place of death = death_place_display\n",
    "- cause of death = cause_of_death_display [x]\n",
    "- date of death = death_date_year_transcribed [x]\n",
    "- undertaker = undertaker_display\n",
    "- burial registry = interment_id, registry_volume\n",
    "- lot number = burial_location_lot_current\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql --conn --close"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
